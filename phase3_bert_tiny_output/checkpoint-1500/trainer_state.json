{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.5567928730512249,
  "eval_steps": 500,
  "global_step": 1500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01855976243504083,
      "grad_norm": 3.0245168209075928,
      "learning_rate": 1.98181143281366e-05,
      "loss": 1.7163,
      "step": 50
    },
    {
      "epoch": 0.03711952487008166,
      "grad_norm": 3.255547523498535,
      "learning_rate": 1.9632516703786194e-05,
      "loss": 1.5904,
      "step": 100
    },
    {
      "epoch": 0.0556792873051225,
      "grad_norm": 1.88540518283844,
      "learning_rate": 1.9446919079435784e-05,
      "loss": 1.538,
      "step": 150
    },
    {
      "epoch": 0.07423904974016332,
      "grad_norm": 2.3468854427337646,
      "learning_rate": 1.9261321455085377e-05,
      "loss": 1.4514,
      "step": 200
    },
    {
      "epoch": 0.09279881217520415,
      "grad_norm": 3.180241823196411,
      "learning_rate": 1.907572383073497e-05,
      "loss": 1.4185,
      "step": 250
    },
    {
      "epoch": 0.111358574610245,
      "grad_norm": 2.325031042098999,
      "learning_rate": 1.889012620638456e-05,
      "loss": 1.4197,
      "step": 300
    },
    {
      "epoch": 0.12991833704528583,
      "grad_norm": 2.1824686527252197,
      "learning_rate": 1.8704528582034153e-05,
      "loss": 1.4017,
      "step": 350
    },
    {
      "epoch": 0.14847809948032664,
      "grad_norm": 1.59360933303833,
      "learning_rate": 1.8518930957683743e-05,
      "loss": 1.3884,
      "step": 400
    },
    {
      "epoch": 0.16703786191536749,
      "grad_norm": 2.94215726852417,
      "learning_rate": 1.8333333333333333e-05,
      "loss": 1.3999,
      "step": 450
    },
    {
      "epoch": 0.1855976243504083,
      "grad_norm": 2.122307777404785,
      "learning_rate": 1.8147735708982926e-05,
      "loss": 1.4114,
      "step": 500
    },
    {
      "epoch": 0.20415738678544915,
      "grad_norm": 3.5280208587646484,
      "learning_rate": 1.796213808463252e-05,
      "loss": 1.3635,
      "step": 550
    },
    {
      "epoch": 0.22271714922049,
      "grad_norm": 1.9275193214416504,
      "learning_rate": 1.777654046028211e-05,
      "loss": 1.3727,
      "step": 600
    },
    {
      "epoch": 0.2412769116555308,
      "grad_norm": 1.993567705154419,
      "learning_rate": 1.7590942835931702e-05,
      "loss": 1.3366,
      "step": 650
    },
    {
      "epoch": 0.25983667409057165,
      "grad_norm": 2.3431334495544434,
      "learning_rate": 1.7405345211581292e-05,
      "loss": 1.2745,
      "step": 700
    },
    {
      "epoch": 0.27839643652561247,
      "grad_norm": 2.7396037578582764,
      "learning_rate": 1.7219747587230886e-05,
      "loss": 1.3416,
      "step": 750
    },
    {
      "epoch": 0.2969561989606533,
      "grad_norm": 4.821883678436279,
      "learning_rate": 1.703414996288048e-05,
      "loss": 1.339,
      "step": 800
    },
    {
      "epoch": 0.31551596139569416,
      "grad_norm": 6.845373630523682,
      "learning_rate": 1.684855233853007e-05,
      "loss": 1.3345,
      "step": 850
    },
    {
      "epoch": 0.33407572383073497,
      "grad_norm": 2.790860176086426,
      "learning_rate": 1.666295471417966e-05,
      "loss": 1.2841,
      "step": 900
    },
    {
      "epoch": 0.3526354862657758,
      "grad_norm": 2.5333755016326904,
      "learning_rate": 1.647735708982925e-05,
      "loss": 1.3303,
      "step": 950
    },
    {
      "epoch": 0.3711952487008166,
      "grad_norm": 3.4808437824249268,
      "learning_rate": 1.629175946547884e-05,
      "loss": 1.3,
      "step": 1000
    },
    {
      "epoch": 0.3897550111358575,
      "grad_norm": 3.298269748687744,
      "learning_rate": 1.6106161841128435e-05,
      "loss": 1.2636,
      "step": 1050
    },
    {
      "epoch": 0.4083147735708983,
      "grad_norm": 3.4991514682769775,
      "learning_rate": 1.5920564216778028e-05,
      "loss": 1.2857,
      "step": 1100
    },
    {
      "epoch": 0.4268745360059391,
      "grad_norm": 3.177908420562744,
      "learning_rate": 1.5734966592427618e-05,
      "loss": 1.2862,
      "step": 1150
    },
    {
      "epoch": 0.44543429844098,
      "grad_norm": 3.6696910858154297,
      "learning_rate": 1.554936896807721e-05,
      "loss": 1.2465,
      "step": 1200
    },
    {
      "epoch": 0.4639940608760208,
      "grad_norm": 2.718693256378174,
      "learning_rate": 1.53637713437268e-05,
      "loss": 1.2362,
      "step": 1250
    },
    {
      "epoch": 0.4825538233110616,
      "grad_norm": 2.822016716003418,
      "learning_rate": 1.5178173719376392e-05,
      "loss": 1.2692,
      "step": 1300
    },
    {
      "epoch": 0.5011135857461024,
      "grad_norm": 3.1322999000549316,
      "learning_rate": 1.4992576095025986e-05,
      "loss": 1.2641,
      "step": 1350
    },
    {
      "epoch": 0.5196733481811433,
      "grad_norm": 3.460967779159546,
      "learning_rate": 1.4806978470675577e-05,
      "loss": 1.3138,
      "step": 1400
    },
    {
      "epoch": 0.5382331106161841,
      "grad_norm": 5.008139133453369,
      "learning_rate": 1.4621380846325169e-05,
      "loss": 1.2714,
      "step": 1450
    },
    {
      "epoch": 0.5567928730512249,
      "grad_norm": 3.7191669940948486,
      "learning_rate": 1.443578322197476e-05,
      "loss": 1.2508,
      "step": 1500
    }
  ],
  "logging_steps": 50,
  "max_steps": 5388,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 5724324864000.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
