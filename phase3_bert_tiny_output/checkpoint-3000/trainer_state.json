{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.1135857461024499,
  "eval_steps": 500,
  "global_step": 3000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01855976243504083,
      "grad_norm": 3.0245168209075928,
      "learning_rate": 1.98181143281366e-05,
      "loss": 1.7163,
      "step": 50
    },
    {
      "epoch": 0.03711952487008166,
      "grad_norm": 3.255547523498535,
      "learning_rate": 1.9632516703786194e-05,
      "loss": 1.5904,
      "step": 100
    },
    {
      "epoch": 0.0556792873051225,
      "grad_norm": 1.88540518283844,
      "learning_rate": 1.9446919079435784e-05,
      "loss": 1.538,
      "step": 150
    },
    {
      "epoch": 0.07423904974016332,
      "grad_norm": 2.3468854427337646,
      "learning_rate": 1.9261321455085377e-05,
      "loss": 1.4514,
      "step": 200
    },
    {
      "epoch": 0.09279881217520415,
      "grad_norm": 3.180241823196411,
      "learning_rate": 1.907572383073497e-05,
      "loss": 1.4185,
      "step": 250
    },
    {
      "epoch": 0.111358574610245,
      "grad_norm": 2.325031042098999,
      "learning_rate": 1.889012620638456e-05,
      "loss": 1.4197,
      "step": 300
    },
    {
      "epoch": 0.12991833704528583,
      "grad_norm": 2.1824686527252197,
      "learning_rate": 1.8704528582034153e-05,
      "loss": 1.4017,
      "step": 350
    },
    {
      "epoch": 0.14847809948032664,
      "grad_norm": 1.59360933303833,
      "learning_rate": 1.8518930957683743e-05,
      "loss": 1.3884,
      "step": 400
    },
    {
      "epoch": 0.16703786191536749,
      "grad_norm": 2.94215726852417,
      "learning_rate": 1.8333333333333333e-05,
      "loss": 1.3999,
      "step": 450
    },
    {
      "epoch": 0.1855976243504083,
      "grad_norm": 2.122307777404785,
      "learning_rate": 1.8147735708982926e-05,
      "loss": 1.4114,
      "step": 500
    },
    {
      "epoch": 0.20415738678544915,
      "grad_norm": 3.5280208587646484,
      "learning_rate": 1.796213808463252e-05,
      "loss": 1.3635,
      "step": 550
    },
    {
      "epoch": 0.22271714922049,
      "grad_norm": 1.9275193214416504,
      "learning_rate": 1.777654046028211e-05,
      "loss": 1.3727,
      "step": 600
    },
    {
      "epoch": 0.2412769116555308,
      "grad_norm": 1.993567705154419,
      "learning_rate": 1.7590942835931702e-05,
      "loss": 1.3366,
      "step": 650
    },
    {
      "epoch": 0.25983667409057165,
      "grad_norm": 2.3431334495544434,
      "learning_rate": 1.7405345211581292e-05,
      "loss": 1.2745,
      "step": 700
    },
    {
      "epoch": 0.27839643652561247,
      "grad_norm": 2.7396037578582764,
      "learning_rate": 1.7219747587230886e-05,
      "loss": 1.3416,
      "step": 750
    },
    {
      "epoch": 0.2969561989606533,
      "grad_norm": 4.821883678436279,
      "learning_rate": 1.703414996288048e-05,
      "loss": 1.339,
      "step": 800
    },
    {
      "epoch": 0.31551596139569416,
      "grad_norm": 6.845373630523682,
      "learning_rate": 1.684855233853007e-05,
      "loss": 1.3345,
      "step": 850
    },
    {
      "epoch": 0.33407572383073497,
      "grad_norm": 2.790860176086426,
      "learning_rate": 1.666295471417966e-05,
      "loss": 1.2841,
      "step": 900
    },
    {
      "epoch": 0.3526354862657758,
      "grad_norm": 2.5333755016326904,
      "learning_rate": 1.647735708982925e-05,
      "loss": 1.3303,
      "step": 950
    },
    {
      "epoch": 0.3711952487008166,
      "grad_norm": 3.4808437824249268,
      "learning_rate": 1.629175946547884e-05,
      "loss": 1.3,
      "step": 1000
    },
    {
      "epoch": 0.3897550111358575,
      "grad_norm": 3.298269748687744,
      "learning_rate": 1.6106161841128435e-05,
      "loss": 1.2636,
      "step": 1050
    },
    {
      "epoch": 0.4083147735708983,
      "grad_norm": 3.4991514682769775,
      "learning_rate": 1.5920564216778028e-05,
      "loss": 1.2857,
      "step": 1100
    },
    {
      "epoch": 0.4268745360059391,
      "grad_norm": 3.177908420562744,
      "learning_rate": 1.5734966592427618e-05,
      "loss": 1.2862,
      "step": 1150
    },
    {
      "epoch": 0.44543429844098,
      "grad_norm": 3.6696910858154297,
      "learning_rate": 1.554936896807721e-05,
      "loss": 1.2465,
      "step": 1200
    },
    {
      "epoch": 0.4639940608760208,
      "grad_norm": 2.718693256378174,
      "learning_rate": 1.53637713437268e-05,
      "loss": 1.2362,
      "step": 1250
    },
    {
      "epoch": 0.4825538233110616,
      "grad_norm": 2.822016716003418,
      "learning_rate": 1.5178173719376392e-05,
      "loss": 1.2692,
      "step": 1300
    },
    {
      "epoch": 0.5011135857461024,
      "grad_norm": 3.1322999000549316,
      "learning_rate": 1.4992576095025986e-05,
      "loss": 1.2641,
      "step": 1350
    },
    {
      "epoch": 0.5196733481811433,
      "grad_norm": 3.460967779159546,
      "learning_rate": 1.4806978470675577e-05,
      "loss": 1.3138,
      "step": 1400
    },
    {
      "epoch": 0.5382331106161841,
      "grad_norm": 5.008139133453369,
      "learning_rate": 1.4621380846325169e-05,
      "loss": 1.2714,
      "step": 1450
    },
    {
      "epoch": 0.5567928730512249,
      "grad_norm": 3.7191669940948486,
      "learning_rate": 1.443578322197476e-05,
      "loss": 1.2508,
      "step": 1500
    },
    {
      "epoch": 0.5753526354862658,
      "grad_norm": 6.416706562042236,
      "learning_rate": 1.425018559762435e-05,
      "loss": 1.1937,
      "step": 1550
    },
    {
      "epoch": 0.5939123979213066,
      "grad_norm": 2.840712785720825,
      "learning_rate": 1.4064587973273945e-05,
      "loss": 1.2187,
      "step": 1600
    },
    {
      "epoch": 0.6124721603563474,
      "grad_norm": 4.7636542320251465,
      "learning_rate": 1.3878990348923535e-05,
      "loss": 1.255,
      "step": 1650
    },
    {
      "epoch": 0.6310319227913883,
      "grad_norm": 5.607141971588135,
      "learning_rate": 1.3693392724573127e-05,
      "loss": 1.2086,
      "step": 1700
    },
    {
      "epoch": 0.6495916852264291,
      "grad_norm": 5.082828998565674,
      "learning_rate": 1.3507795100222718e-05,
      "loss": 1.2316,
      "step": 1750
    },
    {
      "epoch": 0.6681514476614699,
      "grad_norm": 5.916528701782227,
      "learning_rate": 1.332219747587231e-05,
      "loss": 1.2122,
      "step": 1800
    },
    {
      "epoch": 0.6867112100965108,
      "grad_norm": 7.758643627166748,
      "learning_rate": 1.3136599851521901e-05,
      "loss": 1.1647,
      "step": 1850
    },
    {
      "epoch": 0.7052709725315516,
      "grad_norm": 4.318220615386963,
      "learning_rate": 1.2951002227171494e-05,
      "loss": 1.1874,
      "step": 1900
    },
    {
      "epoch": 0.7238307349665924,
      "grad_norm": 8.458266258239746,
      "learning_rate": 1.2765404602821086e-05,
      "loss": 1.2011,
      "step": 1950
    },
    {
      "epoch": 0.7423904974016332,
      "grad_norm": 5.966567516326904,
      "learning_rate": 1.2579806978470678e-05,
      "loss": 1.1631,
      "step": 2000
    },
    {
      "epoch": 0.7609502598366741,
      "grad_norm": 3.820408582687378,
      "learning_rate": 1.2394209354120267e-05,
      "loss": 1.1406,
      "step": 2050
    },
    {
      "epoch": 0.779510022271715,
      "grad_norm": 7.6159210205078125,
      "learning_rate": 1.2208611729769859e-05,
      "loss": 1.2547,
      "step": 2100
    },
    {
      "epoch": 0.7980697847067557,
      "grad_norm": 6.6084113121032715,
      "learning_rate": 1.2023014105419452e-05,
      "loss": 1.1997,
      "step": 2150
    },
    {
      "epoch": 0.8166295471417966,
      "grad_norm": 7.604593753814697,
      "learning_rate": 1.1837416481069044e-05,
      "loss": 1.1448,
      "step": 2200
    },
    {
      "epoch": 0.8351893095768375,
      "grad_norm": 4.749313831329346,
      "learning_rate": 1.1651818856718635e-05,
      "loss": 1.2217,
      "step": 2250
    },
    {
      "epoch": 0.8537490720118782,
      "grad_norm": 2.9473214149475098,
      "learning_rate": 1.1466221232368227e-05,
      "loss": 1.1757,
      "step": 2300
    },
    {
      "epoch": 0.8723088344469191,
      "grad_norm": 7.398604869842529,
      "learning_rate": 1.1280623608017818e-05,
      "loss": 1.1135,
      "step": 2350
    },
    {
      "epoch": 0.89086859688196,
      "grad_norm": 5.541853427886963,
      "learning_rate": 1.109502598366741e-05,
      "loss": 1.2307,
      "step": 2400
    },
    {
      "epoch": 0.9094283593170007,
      "grad_norm": 4.535010814666748,
      "learning_rate": 1.0909428359317003e-05,
      "loss": 1.2119,
      "step": 2450
    },
    {
      "epoch": 0.9279881217520416,
      "grad_norm": 4.22315788269043,
      "learning_rate": 1.0723830734966593e-05,
      "loss": 1.1533,
      "step": 2500
    },
    {
      "epoch": 0.9465478841870824,
      "grad_norm": 6.0952677726745605,
      "learning_rate": 1.0538233110616184e-05,
      "loss": 1.1589,
      "step": 2550
    },
    {
      "epoch": 0.9651076466221232,
      "grad_norm": 3.0166454315185547,
      "learning_rate": 1.0352635486265776e-05,
      "loss": 1.1993,
      "step": 2600
    },
    {
      "epoch": 0.9836674090571641,
      "grad_norm": 5.647500991821289,
      "learning_rate": 1.0167037861915368e-05,
      "loss": 1.1456,
      "step": 2650
    },
    {
      "epoch": 1.0022271714922049,
      "grad_norm": 6.123433589935303,
      "learning_rate": 9.981440237564959e-06,
      "loss": 1.1196,
      "step": 2700
    },
    {
      "epoch": 1.0207869339272457,
      "grad_norm": 6.173016548156738,
      "learning_rate": 9.79584261321455e-06,
      "loss": 1.1612,
      "step": 2750
    },
    {
      "epoch": 1.0393466963622866,
      "grad_norm": 5.463096618652344,
      "learning_rate": 9.610244988864144e-06,
      "loss": 1.1062,
      "step": 2800
    },
    {
      "epoch": 1.0579064587973275,
      "grad_norm": 4.243912220001221,
      "learning_rate": 9.424647364513735e-06,
      "loss": 1.1548,
      "step": 2850
    },
    {
      "epoch": 1.0764662212323681,
      "grad_norm": 3.4567294120788574,
      "learning_rate": 9.239049740163325e-06,
      "loss": 1.1915,
      "step": 2900
    },
    {
      "epoch": 1.095025983667409,
      "grad_norm": 7.12135124206543,
      "learning_rate": 9.053452115812919e-06,
      "loss": 1.1697,
      "step": 2950
    },
    {
      "epoch": 1.1135857461024499,
      "grad_norm": 5.133857250213623,
      "learning_rate": 8.86785449146251e-06,
      "loss": 1.1273,
      "step": 3000
    }
  ],
  "logging_steps": 50,
  "max_steps": 5388,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 11447934187392.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
