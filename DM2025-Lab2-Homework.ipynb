{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Student Information**\n",
    "Name:高智宣\n",
    "\n",
    "Student ID:112020023\n",
    "\n",
    "GitHub ID:Johanneskoh\n",
    "\n",
    "Kaggle name:智宣_高\n",
    "\n",
    "Kaggle private scoreboard snapshot: \n",
    "\n",
    "![pic_ranking.png](./pics/pic_ranking.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Instructions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab we have divided the assignments into **three phases/parts**. The `first two phases` refer to the `exercises inside the Master notebooks` of the [DM2025-Lab2-Exercise Repo](https://github.com/difersalest/DM2025-Lab2-Exercise.git). The `third phase` refers to an `internal Kaggle competition` that we are gonna run among all the Data Mining students. Together they add up to `100 points` of your grade. There are also some `bonus points` to be gained if you complete `extra exercises` in the lab **(bonus 15 pts)** and in the `Kaggle Competition report` **(bonus 5 pts)**.\n",
    "\n",
    "**Environment recommendations to solve lab 2:**\n",
    "- **Phase 1 exercises:** Need GPU for training the models explained in that part, if you don't have a GPU in your laptop it is recommended to run in Colab or Kaggle for a faster experience, although with CPU they can still be solved but with a slower execution.\n",
    "- **Phase 2 exercises:** We use Gemini's API so everything can be run with only CPU without a problem.\n",
    "- **Phase 3 exercises:** For the competition you will probably need GPU to train your models, so it is recommended to use Colab or Kaggle if you don't have a laptop with a dedicated GPU.\n",
    "- **Optional Ollama Notebook (not graded):** You need GPU, at least 4GB of VRAM with 16 GB of RAM to run the local open-source LLM models. \n",
    "\n",
    "## **Phase 1 (30 pts):**\n",
    "\n",
    "1. __Main Exercises (25 pts):__ Do the **take home exercises** from Sections: `1. Data Preparation` to `9. High-dimension Visualization: t-SNE and UMAP`, in the [DM2025-Lab2-Master-Phase_1 Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_1.ipynb). Total: `8 exercises`. Commit your code and submit the repository link to NTU Cool **`BEFORE the deadline (Nov. 3th, 11:59 pm, Monday)`**\n",
    "\n",
    "2. **Code Comments (5 pts):** **Tidy up the code in your notebook**. \n",
    "\n",
    "## **Phase 2 (30 pts):**\n",
    "\n",
    "1. **Main Exercises (25 pts):** Do the remaining **take home exercises** from Section: `2. Large Language Models (LLMs)` in the [DM2025-Lab2-Master-Phase_2_Main Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_2_Main.ipynb). Total: `5 exercises required from sections 2.1, 2.2, 2.4 and 2.6`. Commit your code and submit the repository link to NTU Cool **`BEFORE the deadline (Nov. 24th, 11:59 pm, Monday)`**\n",
    "\n",
    "2. **Code Comments (5 pts):** **Tidy up the code in your notebook**. \n",
    "\n",
    "3. **`Bonus (15 pts):`** Complete the bonus exercises in the [DM2025-Lab2-Master-Phase_2_Bonus Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_2_Bonus.ipynb) and [DM2025-Lab2-Master-Phase_2_Main Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_2_Main.ipynb) `where 2 exercises are counted as bonus from sections 2.3 and 2.5 in the main notebook`. Total: `7 exercises`. Commit your code and submit the repository link to NTU Cool **`BEFORE the deadline (Nov. 24th, 11:59 pm, Monday)`**\n",
    "\n",
    "## **Phase 3 (40 pts):**\n",
    "\n",
    "1. **Kaggle Competition Participation (30 pts):** Participate in the in-class **Kaggle Competition** regarding Emotion Recognition on Twitter by clicking in this link: **[Data Mining Class Kaggle Competition](https://www.kaggle.com/t/3a2df4c6d6b4417e8bf718ed648d7554)**. The scoring will be given according to your place in the Private Leaderboard ranking: \n",
    "    - **Bottom 40%**: Get 20 pts of the 30 pts in this competition participation part.\n",
    "\n",
    "    - **Top 41% - 100%**: Get (0.6N + 1 - x) / (0.6N) * 10 + 20 points, where N is the total number of participants, and x is your rank. (ie. If there are 100 participants and you rank 3rd your score will be (0.6 * 100 + 1 - 3) / (0.6 * 100) * 10 + 20 = 29.67% out of 30%.)   \n",
    "    Submit your last submission **`BEFORE the deadline (Nov. 24th, 11:59 pm, Monday)`**. Make sure to take a screenshot of your position at the end of the competition and store it as `pic_ranking.png` under the `pics` folder of this repository and rerun the cell **Student Information**.\n",
    "\n",
    "2. **Competition Report (10 pts)** A report section to be filled in inside this notebook in Markdown Format, we already provided you with the template below. You need to describe your work developing the model for the competition. The report should include a section describing briefly the following elements: \n",
    "* Your preprocessing steps.\n",
    "* The feature engineering steps.\n",
    "* Explanation of your model.\n",
    "\n",
    "* **`Bonus (5 pts):`**\n",
    "    * You will have to describe more detail in the previous steps.\n",
    "    * Mention different things you tried.\n",
    "    * Mention insights you gained. \n",
    "\n",
    "[Markdown Guide - Basic Syntax](https://www.markdownguide.org/basic-syntax/)\n",
    "\n",
    "**`Things to note for Phase 3:`**\n",
    "\n",
    "* **The code used for the competition should be in this Jupyter Notebook File** `DM2025-Lab2-Homework.ipynb`.\n",
    "\n",
    "* **Push the code used for the competition to your repository**.\n",
    "\n",
    "* **The code should have a clear separation for the same sections of the report, preprocessing, feature engineering and model explanation. Briefly comment your code for easier understanding, we provide a template at the end of this notebook.**\n",
    "\n",
    "* Showing the kaggle screenshot of the ranking plus the code in this notebook will ensure the validity of your participation and the report to obtain the corresponding points.\n",
    "\n",
    "After the competition ends you will have two days more to submit the `DM2025-Lab2-Homework.ipynb` with your report in markdown format and your code. Do everything **`BEFORE the deadline (Nov. 26th, 11:59 pm, Wednesday) to obtain 100% of the available points.`**\n",
    "\n",
    "Upload your files to your repository then submit the link to it on the corresponding NTU Cool assignment.\n",
    "\n",
    "## **Deadlines:**\n",
    "\n",
    "![lab2_deadlines](./pics/lab2_deadlines.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Next you will find the template report with some simple markdown syntax explanations, use it to structure your content.\n",
    "\n",
    "You can delete the syntax suggestions after you use them.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# **Project Report**\n",
    "\n",
    "## 1. Model Development (10 pts Required)\n",
    "\n",
    "**Describe briefly each section, you can add graphs/charts to support your explanations.**\n",
    "\n",
    "### 1.1 Preprocessing Steps\n",
    "\n",
    "- **Data cleaning / normalization**\n",
    "  - Remove/replace obvious noise (extra whitespace, repeated punctuation, stray symbols).\n",
    "  - Convert text to a consistent format (e.g., **lowercasing** if the dataset is case-insensitive).\n",
    "  - Handle missing or empty texts by either removing those rows or filling with an empty string (then filtering).\n",
    "\n",
    "- **Tokenization**\n",
    "  - Split each document into tokens using a consistent tokenizer (e.g., regex-based tokenizer or NLTK tokenizer).\n",
    "  - Keep tokens that carry semantic meaning (e.g., alphabetic tokens), and optionally keep contractions depending on the dataset style.\n",
    "\n",
    "- **Stopword removal (optional but common)**\n",
    "  - Remove common stopwords to reduce non-informative features.\n",
    "  - Note: For some datasets, stopwords can still matter (tone/style), so this step can be toggled and compared.\n",
    "\n",
    "- **Lemmatization / stemming (optional)**\n",
    "  - Apply lemmatization (preferred) or stemming to reduce inflected forms into a base form (e.g., “running” → “run”).\n",
    "  - This can reduce sparsity in the feature space, especially for Bag-of-Words models.\n",
    "\n",
    "- **Train/validation/test split**\n",
    "  - Split the dataset into train and test sets (and validation if needed).\n",
    "  - Use **stratified splitting** to preserve class proportions across sets.\n",
    "\n",
    "- **Label preparation**\n",
    "  - Convert category labels into a consistent format (e.g., integer labels or category names).\n",
    "  - Verify the alignment: **number of texts == number of labels** after any filtering.\n",
    "\"\"\"\n",
    "\n",
    "### 1.2 Feature Engineering Steps\n",
    "\n",
    "- **Baseline feature: Term-Document Matrix (TDM / Bag-of-Words)**\n",
    "  - Use a vectorizer (e.g., `CountVectorizer`) to convert tokens into word-frequency features.\n",
    "  - This produces a sparse matrix where each column is a vocabulary term and each row is a document.\n",
    "\n",
    "- **TF-IDF features**\n",
    "  - Use `TfidfVectorizer` to compute TF-IDF weights instead of raw counts.\n",
    "  - Motivation: TF-IDF down-weights very common terms and up-weights more discriminative terms, often improving probabilistic text classifiers.\n",
    "\n",
    "- **N-grams (optional extension)**\n",
    "  - Add **bigrams** (and possibly trigrams) to capture short phrases (e.g., “not good”, “very happy”) that single words may miss.\n",
    "  - This is especially helpful for sentiment/emotion datasets where local patterns matter.\n",
    "\n",
    "- **Augmented features (if you used an augmented TDM)**\n",
    "  - Concatenate additional numeric/text-derived features with the text matrix, such as:\n",
    "    - document length (token count),\n",
    "    - punctuation counts (e.g., exclamation marks),\n",
    "    - presence of negation words (e.g., “not”, “never”),\n",
    "    - keyword indicators or simple lexicon-based counts.\n",
    "  - Ensure all extra features are **numeric** and correctly aligned row-by-row with the text feature matrix before concatenation.\n",
    "\n",
    "- **Feature sanity checks**\n",
    "  - Confirm matrix shapes and alignment (e.g., `X.shape[0] == len(y)`).\n",
    "  - Inspect vocabulary size and sparsity to ensure the vectorizer settings are reasonable (e.g., `min_df`, `max_df` if applied).\n",
    "\"\"\"\n",
    "\n",
    "### 1.3 Explanation of Your Model\n",
    "\n",
    "- **Model choice: Naive Bayes for text classification**\n",
    "  - I used a **Multinomial Naive Bayes** classifier, which is well-suited for high-dimensional sparse text features (Bag-of-Words / TF-IDF).\n",
    "  - The model estimates the probability of a class given a document:\n",
    "    - \\[\n",
    "      P(c \\mid d) \\propto P(c)\\prod_{i} P(w_i \\mid c)\n",
    "      \\]\n",
    "    - where \\(P(c)\\) is the class prior and \\(P(w_i \\mid c)\\) is the likelihood of token \\(w_i\\) under class \\(c\\).\n",
    "\n",
    "- **Why it works well for text**\n",
    "  - Text feature spaces are typically sparse and large; Naive Bayes handles this efficiently.\n",
    "  - Even though it assumes **conditional independence** between words (a simplification), it often performs strongly in practice for document classification.\n",
    "\n",
    "- **Two variants used**\n",
    "  - **NB with word-frequency (TDM)**: uses raw counts; tends to emphasize frequently repeated words in a class.\n",
    "  - **NB with TF-IDF**: uses weighted features; tends to emphasize discriminative words rather than common ones.\n",
    "\n",
    "- **How predictions are made**\n",
    "  - For a new text, it is transformed using the **same vectorizer** (Count/TF-IDF).\n",
    "  - The classifier computes the posterior score for each class and outputs the class with the highest score.\n",
    "\n",
    "- **Evaluation**\n",
    "  - Performance is measured using metrics such as **accuracy**, and preferably also **precision/recall/F1** (macro-F1 if classes are imbalanced).\n",
    "  - A **confusion matrix** is useful to identify which categories are frequently confused and why.\n",
    "\"\"\"\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Bonus Section (5 pts Optional)\n",
    "\n",
    "**Add more detail in previous sections**\n",
    "\n",
    "### 2.1 Mention Different Things You Tried\n",
    "\n",
    "[Content for Experiments]\n",
    "\n",
    "### 2.2 Mention Insights You Gained\n",
    "\n",
    "[Content for Insights]\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`From here on starts the code section for the competition.`**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Competition Code**\n",
    "\n",
    "## 1. Preprocessing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (47890, 4)  Test size: (16281, 4)\n",
      "清洗後示例： I bet there is an army of married couples who did the same exact thing.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "df_id = pd.read_csv('data_identification.csv')\n",
    "df_emotion = pd.read_csv('emotion.csv')\n",
    "\n",
    "with open('final_posts.json', 'r', encoding='utf-8') as f:\n",
    "    data_posts = json.load(f)\n",
    "\n",
    "posts_list = []\n",
    "for item in data_posts:\n",
    "    post_id = item['root']['_source']['post']['post_id']\n",
    "    text = item['root']['_source']['post']['text']\n",
    "    posts_list.append({'id': post_id, 'text': text})\n",
    "\n",
    "df_posts = pd.DataFrame(posts_list)\n",
    "\n",
    "df_merged = pd.merge(df_id, df_posts, on='id', how='left')\n",
    "df_merged = pd.merge(df_merged, df_emotion, on='id', how='left')\n",
    "\n",
    "df_train = df_merged[df_merged['split'] == 'train'].copy()\n",
    "df_test  = df_merged[df_merged['split'] == 'test'].copy()\n",
    "\n",
    "print(\"Train size:\", df_train.shape, \" Test size:\", df_test.shape)\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', ' ', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'@\\w+', ' ', text)\n",
    "    text = re.sub(r'<.*?>', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "df_train['clean_text'] = df_train['text'].apply(clean_text)\n",
    "df_test['clean_text']  = df_test['text'].apply(clean_text)\n",
    "\n",
    "X_train_text = df_train['clean_text']\n",
    "y_train      = df_train['emotion']\n",
    "X_test_text  = df_test['clean_text']\n",
    "\n",
    "print(\"清洗後示例：\", X_train_text.iloc[0][:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF (word) 轉換中...\n",
      "TF-IDF (char) 轉換中...\n",
      "最終特徵維度： (47890, 178156)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "tfidf_word = TfidfVectorizer(\n",
    "    max_features=30000,\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2,\n",
    "    stop_words='english',\n",
    "    sublinear_tf=True\n",
    ")\n",
    "\n",
    "tfidf_char = TfidfVectorizer(\n",
    "    analyzer='char',\n",
    "    ngram_range=(3, 5),\n",
    "    min_df=3,\n",
    "    sublinear_tf=True\n",
    ")\n",
    "\n",
    "print(\"TF-IDF (word) 轉換中...\")\n",
    "X_train_word = tfidf_word.fit_transform(X_train_text)\n",
    "X_test_word  = tfidf_word.transform(X_test_text)\n",
    "\n",
    "print(\"TF-IDF (char) 轉換中...\")\n",
    "X_train_char = tfidf_char.fit_transform(X_train_text)\n",
    "X_test_char  = tfidf_char.transform(X_test_text)\n",
    "\n",
    "X_train_all = hstack([X_train_word, X_train_char])\n",
    "X_test_all  = hstack([X_test_word,  X_test_char])\n",
    "\n",
    "print(\"最終特徵維度：\", X_train_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Implementation Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "開始訓練 Ensemble 模型（三個子模型）...\n",
      "訓練完成。\n",
      "訓練集 accuracy(僅供參考): 0.9757\n",
      "預測測試集...\n",
      "完成!submission 檔案已輸出為: submission_phase3_ensemble_svm_lr.csv\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "clf_svm_strong = LinearSVC(\n",
    "    C=2.0,\n",
    "    class_weight='balanced',\n",
    "    max_iter=8000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "clf_svm_smooth = LinearSVC(\n",
    "    C=0.8,\n",
    "    class_weight='balanced',\n",
    "    max_iter=8000,\n",
    "    random_state=43\n",
    ")\n",
    "\n",
    "clf_lr = LogisticRegression(\n",
    "    C=1.5,\n",
    "    max_iter=3000,\n",
    "    class_weight='balanced',\n",
    "    n_jobs=-1,\n",
    "    solver='saga',\n",
    "    multi_class='multinomial',\n",
    "    random_state=44\n",
    ")\n",
    "\n",
    "ensemble_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('svm_strong', clf_svm_strong),\n",
    "        ('svm_smooth', clf_svm_smooth),\n",
    "        ('logreg', clf_lr)\n",
    "    ],\n",
    "    voting='hard',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"開始訓練 Ensemble 模型（三個子模型）...\")\n",
    "ensemble_clf.fit(X_train_all, y_train)\n",
    "print(\"訓練完成。\")\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train_pred = ensemble_clf.predict(X_train_all)\n",
    "train_acc = accuracy_score(y_train, train_pred)\n",
    "print(f\"訓練集 accuracy(僅供參考): {train_acc:.4f}\")\n",
    "\n",
    "\n",
    "print(\"預測測試集...\")\n",
    "y_test_pred = ensemble_clf.predict(X_test_all)\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    \"id\": df_test[\"id\"],\n",
    "    \"emotion\": y_test_pred\n",
    "})\n",
    "\n",
    "output_filename = \"submission_phase3_ensemble_svm_lr.csv\"\n",
    "submission_df.to_csv(output_filename, index=False)\n",
    "print(f\"完成!submission 檔案已輸出為: {output_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DM2025-Lab2-Exercise",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
